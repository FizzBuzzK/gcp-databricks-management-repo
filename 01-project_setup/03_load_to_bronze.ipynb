{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9af4b2c-c7d0-436d-9689-72514f31383c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name = \"env\", defaultValue = '', label = 'Enter the environment in lower case')\n",
    "env = dbutils.widgets.get(\"env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1ee0a05-d25e-4716-bb5a-d896ac7e5569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./commons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68e0c138-5acb-4372-b45c-1073b1c0b860",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0545e744-81a4-4031-bab0-aa458a46e4c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# One-time run\n",
    "# to clean up the Delta data + checkpoints (so streaming can start fresh) and reflect changes in tables\n",
    "# dbutils.fs.rm(f\"{bronze}/raw_customer\", True)\n",
    "# dbutils.fs.rm(f\"{bronze}/raw_employee\", True)\n",
    "# dbutils.fs.rm(f\"{bronze}/raw_orderdetails\", True)\n",
    "# dbutils.fs.rm(f\"{bronze}/raw_orders\", True)\n",
    "# dbutils.fs.rm(f\"{bronze}/raw_product\", True)\n",
    "# dbutils.fs.rm(f\"{bronze}/raw_region\", True)\n",
    "# dbutils.fs.rm(f\"{bronze}/raw_warehouse\", True)\n",
    "\n",
    "# dbutils.fs.rm(f\"{checkpoint}/rawCustomerLoad\", True)\n",
    "# dbutils.fs.rm(f\"{checkpoint}/rawEmployeeLoad\", True)\n",
    "# dbutils.fs.rm(f\"{checkpoint}/rawOrderDetailsLoad\", True)\n",
    "# dbutils.fs.rm(f\"{checkpoint}/rawOrdersLoad\", True)\n",
    "# dbutils.fs.rm(f\"{checkpoint}/rawProductLoad\", True)\n",
    "# dbutils.fs.rm(f\"{checkpoint}/rawRegionLoad\", True)\n",
    "# dbutils.fs.rm(f\"{checkpoint}/rawWarehouseLoad\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e486d0ae-dde2-4c91-9836-723fdf5daa3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20595c16-9a7b-4f59-8cb5-e44f00412c2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80314598-e94b-4aff-b137-80c737fe48a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99b9ff71-9492-4870-a078-d42f88fff3ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_Product_Data():\n",
    "    print(\"Reading Raw Product Data: \", end='')\n",
    "    schema = StructType([\n",
    "        StructField(\"ProductID\", StringType()),\n",
    "        StructField(\"ProductName\", StringType()),\n",
    "        StructField(\"CategoryName\", StringType()),\n",
    "        StructField(\"ProductDescription\", StringType()),\n",
    "        StructField(\"ProductStandardCost\", DoubleType()),\n",
    "        StructField(\"ProductListPrice\", DoubleType()),\n",
    "        StructField(\"Profit\", DoubleType())\n",
    "    ])\n",
    "\n",
    "    df = (spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"csv\")\n",
    "            .option(\"cloudFiles.schemaLocation\", f\"{checkpoint}/rawProductLoad/schemaInfer\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .schema(schema)\n",
    "            .load(landing + \"/raw_product/\")\n",
    "         )\n",
    "    print(\"Success!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e52fa945-6793-4d46-9443-edff14f40f77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_Orders_Data():\n",
    "    print(\"Reading Raw Orders Data: \", end='')\n",
    "    schema = StructType([\n",
    "        StructField(\"OrderID\", IntegerType()),\n",
    "        StructField(\"OrderDate\", StringType()),\n",
    "        StructField(\"CustomerID\", IntegerType())\n",
    "    ])\n",
    "\n",
    "    df = (spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"csv\")\n",
    "            .option(\"cloudFiles.schemaLocation\", f\"{checkpoint}/rawOrdersLoad/schemaInfer\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .schema(schema)\n",
    "            .load(landing + \"/raw_orders/\")\n",
    "         )\n",
    "    print(\"Success!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37e59769-137f-4e6e-880f-34f8d0d9d52b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_Customer_Data():\n",
    "    print(\"Reading Raw Customer Data: \", end='')\n",
    "    schema = StructType([\n",
    "        StructField(\"CustomerID\", IntegerType()),\n",
    "        StructField(\"CustomerName\", StringType()),\n",
    "        StructField(\"CustomerEmail\", StringType()),\n",
    "        StructField(\"CustomerPhone\", StringType()),\n",
    "        StructField(\"CustomerAddress\", StringType()),\n",
    "        StructField(\"CustomerCreditLimit\", IntegerType())\n",
    "    ])\n",
    "\n",
    "    df = (spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"csv\")\n",
    "            .option(\"cloudFiles.schemaLocation\", f\"{checkpoint}/rawCustomerLoad/schemaInfer\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .schema(schema)\n",
    "            .load(landing + \"/raw_customer/\")\n",
    "         )\n",
    "    print(\"Success!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "510b671a-4968-410c-abc8-56831ca92061",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_Warehouse_Data():\n",
    "    print(\"Reading Raw Warehouse Data: \", end='')\n",
    "    schema = StructType([\n",
    "        StructField(\"WarehouseID\", IntegerType()),\n",
    "        StructField(\"WarehouseName\", StringType()),\n",
    "        StructField(\"WarehouseAddress\", StringType()),\n",
    "        StructField(\"RegionID\", IntegerType())\n",
    "    ])\n",
    "\n",
    "    df = (spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"csv\")\n",
    "            .option(\"cloudFiles.schemaLocation\", f\"{checkpoint}/rawWarehouseLoad/schemaInfer\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .schema(schema)\n",
    "            .load(landing + \"/raw_warehouse/\")\n",
    "         )\n",
    "    print(\"Success!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fba1b2dc-9599-4d8e-b2ee-a06637a8caeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_Employee_Data():\n",
    "    print(\"Reading Raw Employee Data: \", end='')\n",
    "    schema = StructType([\n",
    "        StructField(\"EmployeeID\", IntegerType()),\n",
    "        StructField(\"EmployeeName\", StringType()),\n",
    "        StructField(\"EmployeeEmail\", StringType()),\n",
    "        StructField(\"EmployeePhone\", StringType()),\n",
    "        StructField(\"EmployeeHireDate\", StringType()),\n",
    "        StructField(\"EmployeeJobTitle\", StringType()),\n",
    "        StructField(\"WarehouseID\", IntegerType())\n",
    "    ])\n",
    "\n",
    "    df = (spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"csv\")\n",
    "            .option(\"cloudFiles.schemaLocation\", f\"{checkpoint}/rawEmployeeLoad/schemaInfer\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .schema(schema)\n",
    "            .load(landing + \"/raw_employee/\")\n",
    "         )\n",
    "    print(\"Success!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9034c23c-58b9-41a7-a124-2ae5916aaea6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_Region_Data():\n",
    "    print(\"Reading Raw Region Data: \", end='')\n",
    "    schema = StructType([\n",
    "        StructField(\"RegionID\", IntegerType()),\n",
    "        StructField(\"RegionName\", StringType()),\n",
    "        StructField(\"CountryName\", StringType()),\n",
    "        StructField(\"State\", StringType()),\n",
    "        StructField(\"City\", StringType()),\n",
    "        StructField(\"PostalCode\", StringType())\n",
    "    ])\n",
    "\n",
    "    df = (spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"csv\")\n",
    "            .option(\"cloudFiles.schemaLocation\", f\"{checkpoint}/rawRegionLoad/schemaInfer\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .schema(schema)\n",
    "            .load(landing + \"/raw_region/\")\n",
    "         )\n",
    "    print(\"Success!\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaad92ea-67bf-4132-a47a-60f8b13cfdc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_OrderDetails_Data():\n",
    "    print(\"Reading Raw OrderDetails Data: \", end='')\n",
    "    schema = StructType([\n",
    "        StructField(\"OrderDetailsID\", IntegerType()),\n",
    "        StructField(\"ProductID\", StringType()),\n",
    "        StructField(\"OrderItemQuantity\", IntegerType()),\n",
    "        StructField(\"PerUnitPrice\", DoubleType()),\n",
    "        StructField(\"OrderStatus\", StringType()),\n",
    "        StructField(\"OrderID\", IntegerType())\n",
    "    ])\n",
    "\n",
    "    df = (spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"csv\")\n",
    "            .option(\"cloudFiles.schemaLocation\", f\"{checkpoint}/rawOrderDetailsLoad/schemaInfer\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .schema(schema)\n",
    "            .load(landing + \"/raw_orderdetails/\")\n",
    "         )\n",
    "    print(\"Success!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bea924fb-db3a-4c2b-badc-0fd1fa0287e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_to_bronze(streaming_df, environment, table_name, chk_subdir):\n",
    "    print(f\"Writing data to `{environment}_catalog`.`bronze`.`{table_name}` ... \", end='')\n",
    "    query = (streaming_df.writeStream\n",
    "                .format(\"delta\")\n",
    "                .option(\"checkpointLocation\", f\"{checkpoint}/{chk_subdir}/Checkpt\")\n",
    "                .outputMode(\"append\")\n",
    "                .queryName(f\"{table_name}_WriteStream\")\n",
    "                .trigger(availableNow=True)\n",
    "                .toTable(f\"`{environment}_catalog`.`bronze`.`{table_name}`\"))\n",
    "    query.awaitTermination()\n",
    "    print(\"Success!\")\n",
    "    print(\"******************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c136d0e3-934b-4f2c-b560-c7468f7ad128",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------- Read from landing ----------\n",
    "df_product = read_Product_Data()\n",
    "df_orders = read_Orders_Data()\n",
    "df_customer = read_Customer_Data()\n",
    "df_warehouse = read_Warehouse_Data()\n",
    "df_employee = read_Employee_Data()\n",
    "df_region = read_Region_Data()\n",
    "df_orderdetails = read_OrderDetails_Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1cb7053-8226-4c25-8df4-35b5a547b580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load raw data to bronze tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f93ab18-7dcb-484f-a691-ed97ec61901e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------- Write to bronze ----------\n",
    "write_to_bronze(df_product, env, \"raw_product\", \"rawProductLoad\")\n",
    "write_to_bronze(df_orders, env, \"raw_orders\", \"rawOrdersLoad\")\n",
    "write_to_bronze(df_customer, env, \"raw_customer\", \"rawCustomerLoad\")\n",
    "write_to_bronze(df_warehouse, env, \"raw_warehouse\", \"rawWarehouseLoad\")\n",
    "write_to_bronze(df_employee, env, \"raw_employee\", \"rawEmployeeLoad\")\n",
    "write_to_bronze(df_region, env, \"raw_region\", \"rawRegionLoad\")\n",
    "write_to_bronze(df_orderdetails, env, \"raw_orderdetails\", \"rawOrderDetailsLoad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2988443c-4f75-4875-817d-c807767e8021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Display sample data in bronze tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daeb397c-da76-4bc9-a092-10d7943548e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT * FROM `{env}_catalog`.`bronze`.`raw_product` LIMIT 10\"))\n",
    "display(spark.sql(f\"SELECT * FROM `{env}_catalog`.`bronze`.`raw_orders` LIMIT 10\"))\n",
    "display(spark.sql(f\"SELECT * FROM `{env}_catalog`.`bronze`.`raw_orderdetails` LIMIT 10\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_load_to_bronze",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "3da852ba-03ac-4720-a4cb-e7fc1ea8c879",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
